%author Alexander Feng
% This question arises from a natural question: DFT for diagonalization?
% Credit to Gilbert Strang from MIT for setting the basis to write this question.
% In particular, his book on Linear Algebra and Learning From Data Page 215.

\qns{DFT as a basis for Diagonalization}

Looking at a DFT matrix, notice how the DFT matrix's columns could form a very nice basis.
In fact, a natural question to ask is what types of matrices can be diagonalized by the DFT?
Let's start with a motivating example.

\begin{enumerate}

\qitem
What's the following matrix's eigenvectors?

{\em HINT: Don't use the determinant. Try guessing and noticing the special properties of the matrix.}
\begin{align*}
  A =
\begin{bmatrix}
1 & 4 & 3 & 2 \\
2 & 1 & 4 & 3 \\
3 & 2 & 1 & 4 \\
4 & 3 & 2 & 1 \\
\end{bmatrix}
\end{align*}

\sol{
The most obvious guess is try a vector of only ones because each row adds up to 10.
This has eigenvalue 10.
Afterwards, we can leverage the cyclic nature of the rows, and find another eigenvector in
$\begin{bmatrix}
1\\
-1\\
1\\
-1\\
\end{bmatrix}$
This vector has eigenvalue -2.
Taking a very wild guess, well try using gram schmidt to figure out the next eigenvectors.
Perhaps we'll be lucky.
What you'll find is that the other two eigenvectors are in fact the other two basis vectors for a size 4 DFT matrix!
Thus, the eigenvectors (unnormalized) are:
\begin{align*}
  \{
\begin{bmatrix}
1\\
1\\
1\\
1\\
\end{bmatrix},
\begin{bmatrix}
1\\
\omega\\
\omega^{2}\\
\omega^{3}\\
\end{bmatrix},
\begin{bmatrix}
1\\
\omega^{3}\\
\omega^{6}\\
\omega^{9}\\
\end{bmatrix},
\begin{bmatrix}
1\\
\omega^{4}\\
\omega^{8}\\
\omega^{12}\\
\end{bmatrix}
\}
\end{align*}

Note that in gram schmidt, you would apply a normalization factor to each DFT basis vector.
}

\qitem
This seems quite interesting.
Let's try generalizing the matrix from part (a).
We define a permutation matrix as a matrix who has exactly one entry of 1 in each row.
You can think of this as an identity matrix with all of its rows scrambled about.
Write the matrix $A$ from part (a) as a sum of permutation matrices.

\sol{
What we find as our solution is the following:
\begin{align*}
A = 1I + 2
\begin{bmatrix}
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
\end{bmatrix}
+ 3
\begin{bmatrix}
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
\end{bmatrix}
+ 4
\begin{bmatrix}
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \\
\end{bmatrix}
\end{align*}
}

\qitem
From part (b), you should notice that there's an interesting cyclic rotation of rows in the permutation matrices.
We define the permutation matrix $P$ as follows:
\begin{align*}
P =
\begin{bmatrix}
0 & 0 & 0 & 1\\
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
\end{bmatrix}
\end{align*}

Write all the other permutation matrices from part (b) in terms of $P$.
Then, rewrite all the matrix $A$ in terms of permutation matrices.

\sol{

First, if we define the matrices $P_{i}$ the following manner where $P$ is the same as $P_{1}$:

\begin{align*}
P = P_{1} =
\begin{bmatrix}
0 & 0 & 0 & 1\\
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
\end{bmatrix}
\hspace{1em}
P_{2} =
\begin{bmatrix}
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
\end{bmatrix}
\hspace{1em}
P_{3} =
\begin{bmatrix}
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
\end{bmatrix}
\end{align*}

Notice that when $P_{1}$ multiplies a vector, it performs a row circular shift of all the elements.
When $P_{1}$ multiplies itself, it performs one circular row shift.
Thus, $P_{1}^{2} = P_{2}$ and $P_{1}^{3} = P_{3}$.
In general, $n$ circular row shifts in a permutation matrix is characterized by $P_{n}$ = $P_{1}^{n} = P^{n}$.
This means that if we rewrote the solution to part (b) as $A = 1I + 2P_{1} + 3P_{2} + 4P_{3}$, we could rewrite it in terms of $P = P_{1}$ as $A = 1I + 2P^{1} + 3P^{2} + 4P^{3}$.
}

\qitem
For the 4x4 case, notice that $P^{4} = I$.
For the NxN case, it's simple to also prove that $P^{N} = I$.
This stems from how $P$ multiply $P$ produces one circular row shift.
Very quickly, we can see the nature of the permutation matrices as eerily similar to the roots of unity.
Perhaps we can discern the relationship between a permutation matrix, its eigenvectors, and its eigenvalues.
Given the permutation matrix $P$ as defined before.
Suppose that we have the eigenvalue $\lambda$ and the vector
\begin{align*}
\vec{x} =
\begin{bmatrix}
x_{1}\\
x_{2}\\
x_{3}\\
x_{4}
\end{bmatrix}
\end{align*}
What's the relationship between each of the elements of $\vec{x}$ and the eigenvalues?


\sol{
Multiplying everything out, we observe that
\begin{align*}
P\vec{x} =
\lambda
\begin{bmatrix}
x_{2}\\
x_{3}\\
x_{4}\\
x_{5}
\end{bmatrix} \implies
\begin{aligned}
x_{1} = \lambda x_{2} \\
x_{2} = \lambda x_{3} \\
x_{3} = \lambda x_{4} \\
x_{4} = \lambda x_{1} \\
\end{aligned}
\implies
x_{1} = \lambda x_{2} = \lambda^{2} x_{3} = \lambda^{3}x_{4} = \lambda^{4}x_{1}
\end{align*}
What set of numbers could constitute these eigenvalues?
The roots of unity!
For a matrix that can be written in terms of $P$, its eigenvalues and eigenvectors are the roots of unity and the DFT basis vectors!
Though, we didn't prove it here rigorously, you can generalize the idea just illustrated to any size circulant matrix.
}

\qitem
Matrices that can be decomposed in terms of permutation matrices are called circulant matrices.
From wikipedia, ``a circulant matrix is a square matrix in which each row vector is rotated one element to the right relative to the preceding row vector''.
Generalizing the information we've obtained from previous parts, what are the eigenvalues of any circulant matrix?

\sol{
Given a circulant matrix $C$, we know that it can be broken down as follows:
\begin{align*}
C = c_{0}I + c_{1}P + c_{2}P^{2} + \dots + c_{n-1}P^{n-1}
\end{align*}
Note that $I = P^{N}$.
When we multiply $C$ by any corresponding eigenvector that we'll call $\vec{q_{i}}$, we have the following:
\begin{align*}
C\vec{q_{i}} = c_{0}I\vec{q_{i}} + c_{1}P\vec{q_{i}} + c_{2}P^{2}\vec{q_{i}} + \dots + c_{n-1}P^{n-1}\vec{q_{i}}
\end{align*}
Thus, the eigenvalues of a circulant matrix are a linear combination of the eigenvalues of the corresponding $P$ matrices.
In other words, for an eigenvector $\vec{q_{i}}$, we have that:
\begin{align*}
\lambda_{i} = c_{0} + c_{1}\omega_{i} + c_{2}\omega_{i}^{2} + \dots + c_{n-1}\omega_{i}^{n-1}
\end{align*}
where $j = 0, 1, \dots, n - 1$. Note that $w_{0} = 1$ and notice how this is a full set of eigenvalues.
}

\qitem
Using what we now know, what are the eigenvectors of any circulant matrix?

\sol{
The easiest way to figure out the answer to (f) out is to use a similar decomposition we used in part (e).
We observe the following after pulling the eigenvector out:
\begin{align*}
C\vec{q_{i}} = c_{0}I\vec{q_{i}} + c_{1}P\vec{q_{i}} + c_{2}P^{2}\vec{q_{i}} + \dots + c_{n-1}P^{n-1}\vec{q_{i}} = (c_{0} + c_{1}\omega_{i} + c_{2}\omega_{i}^{2} + \dots + c_{n-1}\omega_{i}^{n-1})\vec{q_{i}}
\end{align*}
This tells us that the eigenvectors of $C$ are the same eigenvectors of $P$, which means the eigenvectors of a circulant matrix are the columns of the DFT matrix!
}
\end{enumerate}
