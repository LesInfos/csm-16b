% \section*{Midterm 1 Review}

\renewcommand{\arraystretch}{1.25}

\subsection*{State-space models of systems}
In this unit, we are focusing on taking real-world systems and then working with them as matrix-vector equations. The first step to doing this is to represent systems with \textbf{state-space models}. \\
\newline
There are two parts to coming up with a state-space model:
\begin{enumerate}
    \item \textit{Choosing state variables.} These are the quantities that will appear in the $\vec{x}$ vector in an equation like 
    $$\frac{d}{dt}\vec{x}(t) = A\vec{x}(t) + B\vec{u}(t)$$ 
    \item \textit{Finding a differential or recurrence relation involving state variables:} i.e. find $\frac{d}{dt} \vec{x}$ in terms of $\vec{x}$ for a continuous-time system or find $\vec{x}(k + 1)$ in terms of $\vec{x}(k)$ for a discrete-time system. \\
    \newline
    Typically, this consists of filling in the elements of the $A$ matrix and $B$ vector, such as in the following equation:
    \begin{align*}
        \vec{x}(k + 1) = \begin{bmatrix}
            a_{11} & a_{12} \\
            a_{21} & a_{22}
        \end{bmatrix} \vec{x}(k) + \begin{bmatrix} b_1 \\ b_2 \end{bmatrix} u(t)
    \end{align*}
    However, \textbf{non-linear systems} cannot be represented as matrix-vector equations, so the state-space model can look as follows:
    \begin{align*}
        \frac{d}{dt} \vec{x}(t) = \begin{bmatrix}
            x_1^{\,2} + \cos(x_2) \\
            x_1^{\,3} - \sin(x_2)
        \end{bmatrix}
    \end{align*}
\end{enumerate}
For instance, when you analyzed the LRC circuit, you chose the voltage across the capacitor and the current through the inductor as your state variables and then used the current-voltage relationships of capacitors and inductors to come up with the following state-space representation:
\begin{align*}
    \frac{d}{dt} \begin{bmatrix} 
        I_L(t) \\ V_C(t)
    \end{bmatrix} = \begin{bmatrix}
        -R/L & -1/L \\
        1/C & 0
    \end{bmatrix} \begin{bmatrix} 
        I_L(t) \\ V_C(t)
    \end{bmatrix}
    \end{align*}

\subsection*{Linearization}
Many systems in the real world are nonlinear, which means that we cannot represent them with a matrix-vector equation. 
We would like to use linear tools (such as diagonalization) to solve these equations, so we typically linearize nonlinear systems. \\
\newline
\textbf{When is a system linear?} \\
A system is linear if it follows the \textbf{scaling} and \textbf{additivity} properties:
\begin{enumerate}
    \item \textbf{Scaling}: For a linear system $f$, $f(ax) = af(x)$ for every $a$ and for every $x$.
    \item \textbf{Additivity}: For a linear system $f$, $f(x + y) = f(x) + f(y)$ for every $x, y$.
\end{enumerate}
\textit{Note: Equations of the form $f(x) = ax + b$ with nonzero $b$ are not linear; they are considered to be \textbf{affine}}. \\
\newline
\textbf{Linearizing a nonlinear system} \\
We convert a nonlinear system into a linear system by using a first-order Taylor approximation:
$$f(x) \approx f(x^*) + \frac{df}{dx} \bigg\rvert_{x = x^*} (x - x^*)$$
Or, for an equation with an input, $u$:
$$f(x, u) \approx f(x^*, u^*) + \frac{df}{dx} \bigg\rvert_{x = x^*} (x - x^*) + \frac{df}{du} \bigg\rvert_{u = u^*} (u - u^*)$$
In these equations, we linearize the system around an \textbf{equilibrium point} or \textbf{operating point}, $(x^*, u^*)$. 
This is a point that we choose when making our approximation, typically so that
$$f(x^*, u^*) = 0$$
\newline
\textbf{Linearizing a system of nonlinear equations} \\
Say we have a system of nonlinear functions, typically represented by
\begin{align*}
    \vec{f}(\vec{x}) = \begin{bmatrix}
        f_1(x_1, \dots, x_n) \\
        \vdots \\
        f_m(x_1, \dots, x_n)
    \end{bmatrix}
\end{align*}
For these systems, you can linearize each equation using the partial derivative of the function with respect to each state variable:
\begin{center}
    \begin{align*}
        f_1(\vec{x}) \approx f_1(\vec{x}^*) + \frac{\partial f_1}{\partial x_1} \bigg\rvert_{x_1 = x_1^*} (x_1 - x_1^*) + \cdots + \frac{\partial f_1}{\partial x_n} \bigg\rvert_{x_n = x_n^*} (x_n - x_n^*) \\
        \vdots \\
        f_m(\vec{x}) \approx f_m(\vec{x}^*) + \frac{\partial f_m}{\partial x_1} \bigg\rvert_{x_1 = x_1^*} (x_1 - x_1^*) + \cdots + \frac{\partial f_m}{\partial x_n} \bigg\rvert_{x_n = x_n^*} (x_n - x_n^*)
    \end{align*}
\end{center}
In this case, we choose an $\vec{x}^*$ and $\vec{u}^*$ such that $\vec{f}(\vec{x}^*, \vec{u}^*) = \vec{0}$. \\
\newline
We can express this linearization as a matrix-vector equation:
\begin{align*}
    \vec{f}(\vec{x}) = \begin{bmatrix}
        \frac{\partial f_1}{\partial x_1} \bigg\rvert_{x_1^*} & \cdots & \frac{\partial f_1}{\partial x_n} \bigg\rvert_{x_n^*} \\
        \vdots & \ddots & \vdots \\
        \frac{\partial f_m}{\partial x_1} \bigg\rvert_{x_1^*} & \cdots & \frac{\partial f_m}{\partial x_n} \bigg\rvert_{x_n^*}
    \end{bmatrix} \begin{bmatrix}
        (x_1 - x_1^*) \\
        \vdots \\
        (x_n - x_n^*)
    \end{bmatrix} = J_{\vec{x}} \vec{\delta x}
\end{align*}
Where $J_{\vec{x}}$ is the \textbf{Jacobian matrix} of $\vec{f}$ with respect to $\vec{x}$ and $\vec{\delta x}$ is the distance of $\vec{x}$ from the equilibrium point. \\
\newline
If we are looking at a system of equations with a vector input, the linearization will be as follows
\begin{align*}
    \vec{f}(\vec{x}, \vec{u}) = \begin{bmatrix}
        \frac{\partial f_1}{\partial x_1} \bigg\rvert_{x_1^*} & \cdots & \frac{\partial f_1}{\partial x_n} \bigg\rvert_{x_n^*} \\
        \vdots & \ddots & \vdots \\
        \frac{\partial f_m}{\partial x_1} \bigg\rvert_{x_1^*} & \cdots & \frac{\partial f_m}{\partial x_n} \bigg\rvert_{x_n^*}
    \end{bmatrix} \begin{bmatrix}
        (x_1 - x_1^*) \\
        \vdots \\
        (x_n - x_n^*)
    \end{bmatrix} + \begin{bmatrix}
        \frac{\partial f_1}{\partial u_1} \bigg\rvert_{u_1^*} & \cdots & \frac{\partial f_1}{\partial u_k} \bigg\rvert_{u_k^*} \\
        \vdots & \ddots & \vdots \\
        \frac{\partial f_m}{\partial u_1} \bigg\rvert_{u_1^*} & \cdots & \frac{\partial f_m}{\partial u_k} \bigg\rvert_{u_k^*}
    \end{bmatrix} \begin{bmatrix}
        (u_1 - u_1^*) \\
        \vdots \\
        (u_k - u_k^*)
    \end{bmatrix} = J_{\vec{x}} \vec{\delta x} + J_{\vec{u}} \vec{\delta u}
\end{align*}

\subsection*{Discretization}
Another modification we often make is converting systems from \textbf{continuous time} (represented by a \textit{differential equation}) to \textbf{discrete time} (represented by a \textit{recurrence relation}).
One motivation behind discretizing a system is that computers can only sample the system at discrete points in time, and can only provide piecewise constant inputs. \\
\newline
\textbf{Discretizing a system} \\
Let's say you have an differential equation of the form
$$\frac{d}{dt} x = f(t) + u(t)$$
We want to convert it into the discrete-time recurrence relation
$$\tilde{x}(k + 1) = a\tilde{x}(k) + \tilde{u}(k)$$
where $\tilde{x}(k)$ is the discrete-time counterpart of $x(t)$ and $\tilde{u}(k)$ is the discrete-time counterpart of the input $u(t)$.
\newline
We are given our system has time step $T$, which you can think of as having two implications:
\begin{enumerate}
    \item Inputs are constant between times $nT$ and $(n + 1)T$.
    \item When we discretize the system, $\tilde{x}(k) = x(kT)$.
\end{enumerate}
In order to discretize the system, we want to find $x(t + T)$ in terms of $x(t)$, assuming a constant input in the interval $[t, t + T)$.
To do so, you can integrate the system between $t$ and $t + T$:
\begin{align*}
    \int_{x(t)}^{x(t + T)} dx = \int_t^{t + T} (f(\tau) + u(\tau)) \, d\tau \\
\end{align*}
Note that the variable of integration on the right-hand side is $\tau$, not $t$ because $t$ is present in the limits of integration. \\
If $F$ is the antiderivative of $f$, we can get the following expression for $x(t + T)$
\begin{align*}
    x(t + T) = x(t) + (F(t + T) - F(t) + Tu(t))
\end{align*}
Now, we have the information we need to get $\tilde{x}(k + 1)$ in terms of $\tilde{x}(k)$ and $\tilde{u}(k)$. 
If we set $t = kT$, we have
\begin{align*}
    x((k + 1)T) = x(kT) + (F((k + 1)T) - F(kT) + Tu(kT)) \\
    \tilde{x}(k + 1) = \tilde{x}(k) + (F((k + 1)T) - F(kT) + Tu(kT))
\end{align*}
So, in the expression $\tilde{x}(k + 1) = a\tilde{x}(k) + \tilde{u}(k)$, $a = 1$ and $\tilde{u}(k) = F((k + 1)T) - F(kT) + Tu(kT)$.

\subsection*{Controllability}
We say that a system of the form
$$\vec{x}(k + 1) = A\vec{x}(k) + \vec{b} u(k)$$
is controllable if, given any $\vec{x}(0)$, we can specify a series of control inputs $(u(0), u(1), \dots, u(n))$ to reach any state (so, $\vec{x}(n)$ can be anything we want it to be). \\
To determine whether a system is controllable, we define its controllability matrix to be
\begin{align*}
    \mathcal{C} = \begin{bmatrix}
        \vec{b} & A\vec{b} & \cdots & A^{n - 1} \vec{b}
    \end{bmatrix}
\end{align*}
Assuming we start at $\vec{x}(0) = \vec{0}$, we can reach any state in the span of the columns of $\mathcal{C}$, and therefore the system is controllable if the $\mathcal{C}$ is \textbf{full rank}, i.e., for an n-dimensional $\vec{x}$, the controllability matrix has n linearly independent columns. \\
\newline
\textbf{Controlling a system} \\
Assume we have a scalar input $u(k)$ and we want to see what states we can reach with $n$ controls if we start at $\vec{x}(0) = \vec{0}$. \\ 
\newline
Plugging the controls into the recurrence relation, we see that the first column of the controllability matrix corresponds to the last input ($u(n - 1)$), the second column corresponds to the second-to-last input ($u(n - 2)$), and the $n^{\text{th}}$ column corresponds to $u(0)$: 
\begin{align*}
    \vec{x}(n) = A\vec{x}(n - 1) + \vec{b} u(n - 1) \\
    \vec{x}(n) = A(A \vec{x}(n - 2) + \vec{b} u(n - 2)) + \vec{b} u(n - 1) \\
    = A^2 \vec{x}(n - 2) + A\vec{b} u(n - 2) + \vec{b} u(n - 1) \\
    \cdots
    \vec{x}(n) = A^n \vec{x}(0) + A^{n - 1} \vec{b} u(0) + \cdots +  A\vec{b} u(n - 2) + \vec{b} u(n - 1) \\
    = A^{n - 1} \vec{b} u(0) + \cdots +  A\vec{b} u(n - 2) + \vec{b} u(n - 1)
\end{align*}
So, if we want to pick control values such that a system reaches a certain $\vec{x}(n)$ starting at $\vec{x}(0) = \vec{0}$, we can use the relation
\begin{align*}
    \vec{x}(n) = \mathcal{C} \begin{bmatrix}
        u(n - 1) \\ \vdots \\ u(0)
    \end{bmatrix}
\end{align*}
and solve for your control inputs as follows:
\begin{align*}
    \begin{bmatrix}
        u(n - 1) \\ \vdots \\ u(0)
    \end{bmatrix} = \mathcal{C}^{-1} \vec{x}(n)
\end{align*}

\subsection*{System Identification}
If we don't know the parameters of our system (i.e. the $A$ matrix and $\vec{b}$ vector) but we do have a series of inputs and outputs to the system, we can use least squares to solve for the elements of $A$ and $\vec{b}$. \\
\newline
First, let us consider a 2-dimensional system with a scalar input.
\begin{align*}
    \begin{bmatrix}
        x_1(k + 1) \\ x_2(k + 1)
    \end{bmatrix} = \begin{bmatrix}
        a_{11} & a_{12} \\
        a_{21} & a_{22}
    \end{bmatrix} \begin{bmatrix}
        x_1(k) \\ x_2(k)
    \end{bmatrix} + \begin{bmatrix}
        b_1 \\ b_2
    \end{bmatrix} u(k)
\end{align*}
Also, let's say we are given the following data points: $\vec{x}(0), \dots, \vec{x}(m)$ and $u(0), \dots, u(m - 1)$. \\
\newline
In order to perform system identification, we want to format the system as a least squares problem:
\begin{align*}
    D\vec{p} \approx \vec{y}
\end{align*}
$\vec{p}$ is our vector of unknowns, so we populate it with the elements of $A$ and $\vec{b}$:
\begin{align*}
    \vec{p} = \begin{bmatrix}
        a_{11} & a_{12} & a_{21} & a_{22} & b_1 & b_2
    \end{bmatrix}^T
\end{align*}
We can view $\vec{y}$ as the output of the system, so we can populate with $\vec{x}(1), \dots, \vec{x}(m)$
\begin{align*}
    \vec{y} = \begin{bmatrix}
        x_1(1) & x_2(1) & \cdots & x_1(m) & x_2(m)
    \end{bmatrix}^T
\end{align*}
Now, we need to find the elements of the $D$ matrix to complete the relationship between $\vec{p}$ and $\vec{y}$. 
From the matrix-vector representation of the system, we get scalar equations of the form
\begin{align*}
    x_1(k + 1) = a_{11} x_1(k) + a_{12} x_2(k) + b_1 u(k) \\
    x_2(k + 1) = a_{21} x_1(k) + a_{22} x_2(k) + b_2 u(k) 
\end{align*}
So, we have the following least-squares problem:
\begin{align*}
    \begin{bmatrix}
        x_1(1) \\ x_2(1) \\ x_1(2) \\ x_2(2) \cdots \\ x_1(m) \\ x_2(m)
    \end{bmatrix} = \begin{bmatrix}
        x_1(0) & x_2(0) & 0 & 0 & u(0) & 0 \\
        0 & 0 & x_1(0) & x_2(0) & 0 & u(0) \\
        x_1(1) & x_2(1) & 0 & 0 & u(1) & 0 \\
        0 & 0 & x_1(1) & x_2(1) & 0 & u(1) \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
        x_1(m - 1) & x_2(m - 1) & 0 & 0 & u(m - 1) & 0 \\
        0 & 0 & x_1(m - 1) & x_2(m - 1) & 0 & u(m - 1)
    \end{bmatrix} \begin{bmatrix}
        a_{11} \\ a_{12} \\ a_{21} \\ a_{22} \\ b_1 \\ b_2
    \end{bmatrix}
\end{align*}
From here, we can solve for $\vec{p}$ using the least-squares formula:
$$\vec{p} = (D^T D)^{-1} D^T \vec{y}$$
This also extrapolates to systems of higher dimension.
\newline
\textit{Note: At the very least, you need $\vec{x}(0), \dots \vec{x(3)}$ and $u(0), u(1), u(2)$ because we have 6 unknowns and need 6 equations to have a unique solution.}

\subsection*{SVD}